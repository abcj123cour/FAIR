{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Basic example\n",
    "\n",
    "FaIR v2.2 is object-oriented and designed to be more flexible than its predecessors. This does mean that setting up a problem is different to before - gone are the days of 60 keyword arguments to `fair_scm` and we now use classes and functions with fewer arguments that in the long run should be easier to use. Of course, there is a learning curve, and will take some getting used to. This tutorial aims to walk through a simple problem using FaIR 2.2.\n",
    "\n",
    "The structure of FaIR 2.2 centres around the `FAIR` class, which contains all information about the scenario(s), the forcer(s) we want to investigate, and any configurations specific to each species and the response of the climate.\n",
    "\n",
    "## Note\n",
    "\n",
    "The code in this introductory block is explanatory and if you try to copy and paste it it you'll get errors. The code in this file is self-contained below the heading \"1. Create FaIR instance\" below. Alternatively, check out the repository from GitHub and run this example notebook in `jupyter`. Details [here](https://docs.fairmodel.net/en/latest/install.html).\n",
    "\n",
    "## Some basics\n",
    "\n",
    "There are two main parts to running fair. The first is setting up the problem definition. This tells fair what you're including in the run, how long you are running for, how many scenarios and how many (climate) ensemble members (known as configs).\n",
    "\n",
    "### Setting up the run\n",
    "\n",
    "First make a new instance:\n",
    "\n",
    "```\n",
    "from fair import FAIR\n",
    "f = FAIR()\n",
    "```\n",
    "\n",
    "Then, we need to add some information about the time horizon of our model, forcers we want to run with, their configuration (and the configuration of the climate), and optionally some model control options:\n",
    "\n",
    "```\n",
    "from fair.io import read_properties\n",
    "f.define_time(2000, 2050, 1)\n",
    "f.define_scenarios(['abrupt', 'ramp'])\n",
    "f.define_configs(['high', 'central', 'low'])\n",
    "species, properties = read_properties()\n",
    "f.define_species(species, properties)\n",
    "f.ghg_method='Myhre1998'\n",
    "```\n",
    "\n",
    "Finally, we tell fair to generate some empty (all NaN) array variables: emissions, concentrations, forcing, temperature etc.:\n",
    "```\n",
    "f.allocate()\n",
    "```\n",
    "\n",
    "That's all you need to set up the run.\n",
    "\n",
    "### Fill in data\n",
    "\n",
    "The `f.allocate()` step creates `xarray` DataArrays, some of which need to be populated. For example, to fill a constant 40 GtCO2/yr emissions rate for fossil CO2 emissions into the 'abrupt' scenario, we can do\n",
    "\n",
    "```\n",
    "from fair.interface import fill\n",
    "fill(f.emissions, 40, scenario='abrupt', specie='CO2 FFI')\n",
    "...\n",
    "```\n",
    "\n",
    "In this section we also want to tell fair things such as the climate feedback parameter, carbon cycle sensitivities, aerosol forcing parameters, and literally hundreds of other things you can vary. There are convenience functions for reading in emissions and parameter sets from external files.\n",
    "\n",
    "\n",
    "### Run and analyse model\n",
    "\n",
    "Finally, the model is run with\n",
    "\n",
    "```\n",
    "f.run()\n",
    "```\n",
    "\n",
    "Results are stored within the `FAIR` instance as `xarray` DataArrays or Dataset, and can be obtained such as\n",
    "\n",
    "```\n",
    "print(fair.temperature)\n",
    "```\n",
    "\n",
    "Multiple `scenarios` and `configs` can be supplied in a `FAIR` instance, and due to internal parallelisation is the fastest way to run the model (100 ensemble members per second for 1750-2100 on my Mac for an emissions driven run). The total number of scenarios that will be run is the product of `scenarios` and `configs`. For example we might want to run three emissions `scenarios` -- let's say SSP1-2.6, SSP2-4.5 and SSP3-7.0 -- using climate calibrations (`configs`) from the UKESM, GFDL, MIROC and NorESM climate models. This would give us a total of 12 ensemble members in total which are run in parallel.\n",
    "\n",
    "## Recommended order for setting up a problem\n",
    "\n",
    "In this tutorial the recommended order in which to define a problem is set out step by step, and is as follows:\n",
    "\n",
    "1. Create the `FAIR` instance, inititalised with run control options.\n",
    "2. Define the time horizon of the problem with `FAIR.define_time()`\n",
    "3. Define the scenarios to be run (e.g. SSPs, IAM emissions scenarios, or anything you want) with `FAIR.define_scenarios()`.\n",
    "4. Define the configurations to be run with `FAIR.define_configs()`. A configuration (`config`) is a set of parameters that describe climate response and species response parameters. For example you might have a `config` with high climate sensitivity and strong aerosol forcing, and one with low climate sensitivity and weak aerosol forcing.\n",
    "5. Define which `specie`s will be included in the problem, and their properties including the run mode (e.g. emissions-driven, concentration driven) with `FAIR.define_species()`.\n",
    "6. Optionally, modify run control options.\n",
    "7. Create input and output `DataArrays` with `FAIR.allocate()`.\n",
    "8. Fill in the DataArrays (e.g. emissions), climate configs, and species configs, by either working directly with the `xarray` API, or using FaIR-packaged convenience functions like `fill`, `initialise`, `f.fill_from_csv` and `f.override_defaults`.\n",
    "9. Run: `FAIR.run()`.\n",
    "10. Analyse results by accessing the DataArrays that are attributes of `FAIR`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### 1. Create FaIR instance\n",
    "\n",
    "We'll call our instance `f`: it's nice and short and the `fair` name is reserved for the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fair import FAIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FAIR()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### 2. Define time horizon\n",
    "\n",
    "There are two different time indicators in FaIR: the `timebound` and the `timepoint`. `timebound`s, as the name suggests, are at the edges of each time step; they can be thought of as instantaneous snapshots. `timepoint`s are what happens between time bounds and are rates or integral quantities. \n",
    "\n",
    "The main thing to remember is that only `emissions` are defined on `timepoint`s and everything else is defined on `timebound`s, and when we specify the time horizon in our model, we are defining the `timebound`s of the problem.\n",
    "\n",
    "Secondly, the number of `timebound`s is one more than the number of `timepoint`s, as the start and end points are included in the `timebound`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000. 2001. 2002. 2003. 2004. 2005. 2006. 2007. 2008. 2009. 2010. 2011.\n",
      " 2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022. 2023.\n",
      " 2024. 2025. 2026. 2027. 2028. 2029. 2030. 2031. 2032. 2033. 2034. 2035.\n",
      " 2036. 2037. 2038. 2039. 2040. 2041. 2042. 2043. 2044. 2045. 2046. 2047.\n",
      " 2048. 2049. 2050.]\n",
      "[2000.5 2001.5 2002.5 2003.5 2004.5 2005.5 2006.5 2007.5 2008.5 2009.5\n",
      " 2010.5 2011.5 2012.5 2013.5 2014.5 2015.5 2016.5 2017.5 2018.5 2019.5\n",
      " 2020.5 2021.5 2022.5 2023.5 2024.5 2025.5 2026.5 2027.5 2028.5 2029.5\n",
      " 2030.5 2031.5 2032.5 2033.5 2034.5 2035.5 2036.5 2037.5 2038.5 2039.5\n",
      " 2040.5 2041.5 2042.5 2043.5 2044.5 2045.5 2046.5 2047.5 2048.5 2049.5]\n"
     ]
    }
   ],
   "source": [
    "# create time horizon with bounds of 2000 and 2050, at 1-year intervals\n",
    "f.define_time(2000, 2050, 1)\n",
    "print(f.timebounds)\n",
    "print(f.timepoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### 3. Define scenarios\n",
    "\n",
    "The scenarios are a list of strings that label the scenario dimension of the model, helping you keep track of inputs and outputs.\n",
    "\n",
    "In this example problem we will create two scenarios: an \"abrupt\" scenario (where emissions or concentrations change instantly) and a \"ramp\" scenario where they change gradually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abrupt', 'ramp']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define two scenarios\n",
    "f.define_scenarios([\"abrupt\", \"ramp\"])\n",
    "f.scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### 4. Define configs\n",
    "\n",
    "Similarly to the scenarios, the configs are a labelling tool. Each config has associated climate- and species-related settings, which we will come to later. \n",
    "\n",
    "We'll use three config sets, crudely corresponding to high, medium and low climate sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high', 'central', 'low']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define three scenarios\n",
    "f.define_configs([\"high\", \"central\", \"low\"])\n",
    "f.configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### 5. Define species\n",
    "\n",
    "This defines the forcers -- anthropogenic or natural -- that are present in your scenario. A `species` could be something directly emitted like CO2 from fossil fuels, or it could be a category where forcing has to be calculate from precursor emissions like aerosol-cloud interactions.\n",
    "\n",
    "Each `specie` is assigned a name that is used to distinguish it from other species. You can call the species what you like within the model as long as you are consistent. We also pass a dictionary of `properties` that defines how each specie behaves in the model.\n",
    "\n",
    "In this example we'll start off running a scenario with CO2 from fossil fuels and industry, CO2 from AFOLU, CH4, N2O, and Sulfur, and Volcanic forcing (note you don't need the full 40 species used in v1.1-1.6, and some additional default ones are included). From these inputs we also want to determine forcing from aerosol-radiation and aerosol-cloud interactions, as well as CO2, CH4 and N2O.\n",
    "\n",
    "To highlight some of the functionality we'll run CO2 and Sulfur emissions-driven, and CH4 and N2O concentration-driven. (This is akin to an `esm-ssp585` kind of run from CMIP6, though with fewer species). We'll use totally fake data here - this is not intended to represent a real-world scenario but just to highlight how FaIR works. \n",
    "\n",
    "Full simulations may have 50 or more species included and the `properties` dictionary can get quite large, so it can be beneficial to edit it in a CSV and load it in. This is what is done here - we have taken the default `species_configs_properties` file and cut it down to keep only the species we care about.\n",
    "\n",
    "Note the label you have given each specie must appear in the first column of this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fair.io import read_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/importing-data/species_configs_properties.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m species, properties \u001b[38;5;241m=\u001b[39m read_properties(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/importing-data/species_configs_properties.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m f\u001b[38;5;241m.\u001b[39mdefine_species(species, properties)\n",
      "File \u001b[1;32mc:\\Users\\JamesK\\anaconda3\\Lib\\site-packages\\fair\\io\\__init__.py:89\u001b[0m, in \u001b[0;36mread_properties\u001b[1;34m(filename, species)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_properties\u001b[39m(filename\u001b[38;5;241m=\u001b[39mDEFAULT_PROPERTIES_FILE, species\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     70\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a properties file.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03m        species properties that control the FaIR run\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(filename, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m species \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m         species \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(df\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\JamesK\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\JamesK\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\JamesK\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\JamesK\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\JamesK\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/importing-data/species_configs_properties.csv'"
     ]
    }
   ],
   "source": [
    "species, properties = read_properties('data/importing-data/species_configs_properties.csv')\n",
    "f.define_species(species, properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "In total, we have 9 species in this model. We want to run\n",
    "\n",
    "1. CO2 fossil and industry\n",
    "2. CO2 AFOLU\n",
    "3. Sulfur\n",
    "\n",
    "with specified emissions. \n",
    "\n",
    "We want to run\n",
    "\n",
    "4. CH4\n",
    "5. N2O\n",
    "\n",
    "with specified concentrations. We want to include an external time series from\n",
    "\n",
    "6. Volcanic\n",
    "\n",
    "We also want to calculate forcing from CO2, so we need to declare the CO2 as a greenhouse gas in addition to its emitted components:\n",
    "\n",
    "7. CO2\n",
    "\n",
    "and we want to calculate forcing from aerosol radiation and aerosol cloud interactions\n",
    "\n",
    "8. ERFari\n",
    "9. ERFaci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Let's examine them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "`properties` is just a dictionary and `species` just a list. You can define them from scratch, though as you can see even with nine species the dictionary gets quite long so it is easier to read it in. In the `properties` dictionary, the keys must match the `species` that you have declared. \n",
    "\n",
    "The `properties` dictionary contains five keys:\n",
    "\n",
    "- `type` defines the species type such as CO2, an aerosol precursor, or volcanic forcing; there's around 20 pre-defined types in FaIR, and the `type` defines several hard-coded properties about what the specie does. Some can only be defined once per scenario, some can have multiple species attached to its type (e.g. `f-gas`). See the cell below for a list.\n",
    "- `input_mode`: how the model should be driven with this `specie`. Valid values are `emissions`, `concentration`, `forcing` or `calculated` and not all options are valid for all `type`s (e.g. running solar forcing with concentrations). `calculated` means that the emissions/concentration/forcing of this specie depends on others, for example aerosol radiative forcing needs precursors to be emitted.\n",
    "- `greenhouse_gas`: True if the `specie` is a greenhouse gas, which means that an associated `concentration` can be calculated (along with some other species-specific behaviours). Note that CO2 emissions from fossil fuels or from AFOLU are not treated as greenhouse gases.\n",
    "- `aerosol_chemistry_from_emissions`: Some routines such as aerosols, methane lifetime, or ozone forcing, relate to emissions of short-lived climate forcers. If this `specie` is one of these, this should be set to True.\n",
    "- `aerosol_chemistry_from_concentration`: As above, but if the production of ozone, aerosol etc. depends on the concentration of a greenhouse gas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a list of the species types: this cell not necessary for running fair\n",
    "\n",
    "import pandas as pd\n",
    "from fair.structure.species import species_types, valid_input_modes, multiple_allowed\n",
    "\n",
    "types = pd.DataFrame(\n",
    "    {\n",
    "        'type': species_types,\n",
    "        'valid_input_modes': [valid_input_modes[specie] for specie in species_types],\n",
    "        'multiple_allowed': [multiple_allowed[specie] for specie in species_types]\n",
    "    }\n",
    ")\n",
    "types.set_index('type', inplace=True)\n",
    "types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### 6. Modify run options\n",
    "\n",
    "When we initialise the FAIR class, a number of options are given as defaults.\n",
    "\n",
    "Let's say we want to change the greenhouse gas forcing treatment from Meinshausen et al. 2020 default to Myhre et al. 1998. While this could have been done when initialising the class, we can also do it by setting the appropriate attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.ghg_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.ghg_method='myhre1998'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.ghg_method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### 7. Create input and output data\n",
    "\n",
    "Steps 2--5 above dimensioned our problem; now, we want to actually create some data to put into it. \n",
    "\n",
    "First we allocate the data arrays with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.allocate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "This has created our arrays with the correct dimensions as attributes of the `FAIR` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### 8. Fill in the data\n",
    "\n",
    "The data created is nothing more special than `xarray` DataArrays.\n",
    "\n",
    "#### 8a. fill emissions, concentrations ...\n",
    "\n",
    "Using `xarray` methods we can allocate values to the emissions. For example, to fill CO2 fossil emissions in the abrupt scenario with a constant emissions rate of 38 GtCO2/yr (about present-day levels), do:\n",
    "\n",
    "```\n",
    "f.emissions.loc[(dict(specie=\"CO2 FFI\", scenario=\"abrupt\"))] = 38\n",
    "```\n",
    "\n",
    "To do this for every specie, especially if you want to create time-varying scenarios and dimension the scenarios correctly, is very fiddly and time consuming. Therefore, we have a way to read in scenarios from CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.fill_from_csv(\n",
    "    emissions_file='data/basic_run_example/emissions.csv',\n",
    "    concentration_file='data/basic_run_example/concentration.csv',\n",
    "    forcing_file='data/basic_run_example/forcing.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Let's have a look at what we're reading in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data/basic_run_example/emissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data/basic_run_example/concentration.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data/basic_run_example/forcing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "The csv reader will also interpolate, so you don't have to specify every year in your scenario. We have separate functions for reading in files from the Reduced Complexity Model Intercomparison Project (the SSPs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "Note also we haven't filled in every species. CO2 is `calculated` (the sum of `CO2 FFI` and `CO2 AFOLU`), which will correctly determine emissions, concentrations and forcing. Aerosol-radiation interactions and Aerosol-cloud interactions are also `calculated`, from emissions of Sulfur. If the `properties`, particularly `type` and `input_mode` are correctly specified for each specie, `fair` knows what to do with your data. \n",
    "\n",
    "The other thing that we have to do is define the initial conditions of our data. If you forget to do this, you might get NaN value errors in `fair`; this is deliberate, we want the user to think about how they engage with the model!\n",
    "\n",
    "Using non-zero initial conditions can be useful for \"restart runs\": switching from concentration-driven to emissions-driven (ZECMIP); running constant forcing commitments; running interative/adaptive emissions scenarios; the possibilities are endless.\n",
    "\n",
    "As CO2 is emissions-driven, we also need to define its starting concentration.\n",
    "\n",
    "Again, we have a convenience function that can handle some of the heavy lifting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "37",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FAIR' object has no attribute 'concentration'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define initial conditions\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfair\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initialise\n\u001b[0;32m----> 4\u001b[0m initialise(\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcentration\u001b[49m, \u001b[38;5;241m278.3\u001b[39m, specie\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCO2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m initialise(f\u001b[38;5;241m.\u001b[39mforcing, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m initialise(f\u001b[38;5;241m.\u001b[39mtemperature, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FAIR' object has no attribute 'concentration'"
     ]
    }
   ],
   "source": [
    "# Define initial conditions\n",
    "from fair.interface import initialise\n",
    "\n",
    "initialise(f.concentration, 278.3, specie='CO2')\n",
    "initialise(f.forcing, 0)\n",
    "initialise(f.temperature, 0)\n",
    "initialise(f.cumulative_emissions, 0)\n",
    "initialise(f.airborne_emissions, 0)\n",
    "initialise(f.ocean_heat_content_change, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "#### 8b. Fill in `configs`\n",
    "\n",
    "This defines how the forcing is calculated, and how the model responds to a forcing.\n",
    "\n",
    "There are two `xarray.Dataset`s in `fair` that define the behaviour of the model, which are `f.climate_configs` and `f.species_configs`.\n",
    "\n",
    "Many, many `species_configs` parameters have sensible defaults that would make little impact, or little sense, to change. We can add these parameters to the `species_configs_properties` file that we read in earlier that would autopopulate most fields. Let's do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.fill_species_configs('data/importing-data/species_configs_properties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.species_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "However, there's no fun if they are all the same for each config - we want to use fair to sample an ensemble. Again we can read these in, with columns following a naming convention. This also fills the `climate_configs`, which are NaN by default (again we don't want people running things without thinking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.override_defaults('data/basic_run_example/configs_ensemble.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "and this is how it looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data/basic_run_example/configs_ensemble.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "### 9. run FaIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "### 10. plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(f.timebounds, f.temperature.loc[dict(scenario='ramp', layer=0)], label=f.configs)\n",
    "pl.title('Ramp scenario: temperature')\n",
    "pl.xlabel('year')\n",
    "pl.ylabel('Temperature anomaly (K)')\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(f.timebounds, f.concentration.loc[dict(scenario='ramp', specie='CO2')], label=f.configs)\n",
    "pl.title('Ramp scenario: CO2')\n",
    "pl.xlabel('year')\n",
    "pl.ylabel('CO2 (ppm)')\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(f.timebounds, f.forcing.loc[dict(scenario='ramp', specie='Aerosol-cloud interactions')], label=f.configs)\n",
    "pl.title('Ramp scenario: forcing')\n",
    "pl.xlabel('year')\n",
    "pl.ylabel('ERF from aerosol-cloud interactions (W m$^{-2}$)')\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(f.timebounds, f.forcing_sum.loc[dict(scenario='ramp')], label=f.configs)\n",
    "pl.title('Ramp scenario: forcing')\n",
    "pl.xlabel('year')\n",
    "pl.ylabel('Total ERF (W m$^{-2}$)')\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(f.timebounds, f.temperature.loc[dict(scenario='abrupt', layer=0)], label=f.configs)\n",
    "pl.title('Abrupt scenario: temperature')\n",
    "pl.xlabel('year')\n",
    "pl.ylabel('Temperature anomaly (K)')\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(f.timebounds, f.forcing_sum.loc[dict(scenario='abrupt')], label=f.configs)\n",
    "pl.title('Abrupt scenario: forcing')\n",
    "pl.xlabel('year')\n",
    "pl.ylabel('Total ERF (W m$^{-2}$)')\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(f.timebounds, f.concentration.loc[dict(scenario='abrupt', specie='CO2')], label=f.configs)\n",
    "pl.title('Abrupt scenario: CO2')\n",
    "pl.xlabel('year')\n",
    "pl.ylabel('CO2 (ppm)')\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.species_configs['g0'].loc[dict(specie='CO2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.forcing[-1, :, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
